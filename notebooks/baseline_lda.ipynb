{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline LDA model\n",
    "This notebook gives an overview of how to train an LDA model from the Reddit data.\n",
    "\n",
    "The input is a joined submissions and commends dataframe as produced by `notebooks/bagOfWords_preprocessing_databricks.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark configuration:\n",
      "[('spark.app.id', 'local-1645464934358'), ('spark.executor.id', 'driver'), ('spark.driver.port', '40065'), ('spark.app.name', 'baseline lda'), ('spark.driver.memory', '8G'), ('spark.driver.host', '192.168.0.11'), ('spark.sql.warehouse.dir', 'file:/home/virginia/Documents/CenterForDataScience/ZuckermanProj/IHOP/notebooks/spark-warehouse'), ('spark.rdd.compress', 'True'), ('spark.serializer.objectStreamReset', '100'), ('spark.master', 'local[*]'), ('spark.submit.pyFiles', ''), ('spark.submit.deployMode', 'client'), ('spark.executor.extraLibraryPath', '/home/virginia/hadoop-3.3.1/lib/native'), ('spark.ui.showConsoleProgress', 'true'), ('spark.app.startTime', '1645464932414'), ('spark.driver.extraLibraryPath', '/home/virginia/hadoop-3.3.1/lib/native')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import ihop.utils\n",
    "spark = ihop.utils.get_spark_session(\"baseline lda\")\n",
    "\n",
    "input_data = spark.read.load(\n",
    "    \"../data/bagOfWords/2021-05_to_2021-06_joined_submissions_comments_5percentTopUsersExcludedFromComments_02102022.parquet\").limit(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:=====================================================>(199 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+------+-----+--------------------+--------------------+--------------------+-----------+------------------+-----------+----------+--------------+---------+---------------+--------------------+--------------------+--------------------------+\n",
      "|subreddit|    author|created_utc|    id|score|            selftext|               title|                 url|fullname_id|comments_subreddit|comments_id| parent_id|comments_score|  link_id|comments_author|                body|comments_created_utc|time_to_comment_in_seconds|\n",
      "+---------+----------+-----------+------+-----+--------------------+--------------------+--------------------+-----------+------------------+-----------+----------+--------------+---------+---------------+--------------------+--------------------+--------------------------+\n",
      "| Market76|Apostle-II| 1619827212|n26p5s|    2|Don’t use 5.56 an...|H: 30k 50cal and ...|https://www.reddi...|  t3_n26p5s|          Market76|    gwhjcmt| t3_n26p5s|             1|t3_n26p5s|     Apostle-II|    Ultracite 5.56**|          1619827249|                      37.0|\n",
      "| Market76|Apostle-II| 1619827212|n26p5s|    2|Don’t use 5.56 an...|H: 30k 50cal and ...|https://www.reddi...|  t3_n26p5s|          Market76|    gwhjsu2|t1_gwhjnyi|             1|t3_n26p5s|     Apostle-II|                 Gt?|          1619827475|                     263.0|\n",
      "| Market76|Apostle-II| 1619827212|n26p5s|    2|Don’t use 5.56 an...|H: 30k 50cal and ...|https://www.reddi...|  t3_n26p5s|          Market76|    gwhjuvb|t1_gwhjolr|             1|t3_n26p5s|     Apostle-II|Sorry, other pers...|          1619827503|                     291.0|\n",
      "| Market76|Apostle-II| 1619827212|n26p5s|    2|Don’t use 5.56 an...|H: 30k 50cal and ...|https://www.reddi...|  t3_n26p5s|          Market76|    gwhkou5|t1_gwhkglx|             1|t3_n26p5s|     Apostle-II|You mind splittin...|          1619827926|                     714.0|\n",
      "| Market76|Apostle-II| 1619827212|n26p5s|    2|Don’t use 5.56 an...|H: 30k 50cal and ...|https://www.reddi...|  t3_n26p5s|          Market76|    gwhlzxz|t1_gwhjpby|             1|t3_n26p5s|     Apostle-II|15k is what I’m l...|          1619828596|                    1384.0|\n",
      "+---------+----------+-----------+------+-----+--------------------+--------------------+--------------------+-----------+------------------+-----------+----------+--------------+---------+---------------+--------------------+--------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "input_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a simple LDA model using Gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'maxDF'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44556/1631641433.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Tokenize the document, then create an id to word index and vectorize each document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# This is where you would set minimum and maximum document frequency and minimum term frequency, passed to Spark CountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkTextPreprocessingPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'document_text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'maxDF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'minDF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mvectorized_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CenterForDataScience/ZuckermanProj/IHOP/ihop/text_processing.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_col, output_col, tokens_col, tokenization_pattern, match_gaps, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mSpark\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegexTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0msetPattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenization_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0msetGaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_gaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ihop/lib/python3.8/site-packages/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'maxDF'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import ihop.clustering as ic\n",
    "import ihop.text_processing as itp\n",
    "\n",
    "# Read in the joined data, collecting all the comments for each submission\n",
    "# Any desired filtering by time stamps can be done here\n",
    "corpus = itp.SparkCorpus.init_from_joined_dataframe(input_data)\n",
    "\n",
    "# Tokenize the document, then create an id to word index and vectorize each document\n",
    "# This is where you would set minimum and maximum document frequency and minimum term frequency, passed to Spark CountVectorizer\n",
    "pipeline = itp.SparkTextPreprocessingPipeline('document_text', **{'maxDF':0.95, 'minDF':0.05})\n",
    "transformed = pipeline.fit_transform(corpus.document_dataframe)\n",
    "vectorized_corpus = itp.SparkCorpus(transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX DETAILS:\n",
      "Vocab size: 2214\n",
      "0 a\n",
      "1 the\n",
      "2 i\n",
      "3 que\n",
      "4 to\n",
      "5 and\n",
      "6 de\n",
      "7 la\n",
      "8 y\n",
      "9 no\n"
     ]
    }
   ],
   "source": [
    "index = pipeline.get_id_to_word()\n",
    "print(\"INDEX DETAILS:\")\n",
    "print(\"Vocab size:\", len(index))\n",
    "for k in range(10):\n",
    "    print(k, index[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=====================================================>(198 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+\n",
      "|    id|       document_text|           tokenized|          vectorized|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "|n26uxd|Cum visit and cha...|[cum, visit, and,...|(2214,[5,10,13,26...|\n",
      "|n26p5s|H: 30k 50cal and ...|[h, 30k, 50cal, a...|(2214,[0,1,2,4,5,...|\n",
      "|n2725q|hey black jews  Nice|[hey, black, jews...|(2214,[180,432,44...|\n",
      "|n27gmk|Magazine markings...|[magazine, markin...|(2214,[0,1,2,4,5,...|\n",
      "|n272yp|Bulma - lonely mi...|[bulma, lonely, m...|(2214,[0,14,20,38...|\n",
      "|n26rtn|What is always be...|[what, is, always...|(2214,[0,1,2,4,5,...|\n",
      "|n26unv|Lost cat in the S...|[lost, cat, in, t...|(2214,[0,1,4,5,10...|\n",
      "|n26z8u|GUYS THEY ARE STI...|[guys, they, are,...|(2214,[0,1,2,9,10...|\n",
      "|n274xr|Wardens pushing i...|[wardens, pushing...|(2214,[0,1,2,4,5,...|\n",
      "|n272kp|This is my last r...|[this, is, my, la...|(2214,[14,20,24,1...|\n",
      "|n276vv|This week we rele...|[this, week, we, ...|(2214,[0,1,2,4,5,...|\n",
      "|n271bl|Noveske Infidel c...|[noveske, infidel...|(2214,[0,1,2,4,5,...|\n",
      "|n272h4|Who got the best ...|[who, got, the, b...|(2214,[1,15,39,44...|\n",
      "|n26uja|Tell me a bad guy...|[tell, me, a, bad...|(2214,[0,1,13,14,...|\n",
      "|n275j4|I’m waiting for y...|[i’m, waiting, fo...|(2214,[0,1,2,10,1...|\n",
      "|n2712w|Im i the only one...|[im, i, the, only...|(2214,[0,1,2,4,5,...|\n",
      "|n273zc|About the last sp...|[about, the, last...|(2214,[1,2,4,5,10...|\n",
      "|n278ql|I defended an ent...|[i, defended, an,...|(2214,[0,1,2,4,5,...|\n",
      "|n26qdl|[Fabrizio Romano]...|[fabrizio, romano...|(2214,[4,18,21,50...|\n",
      "|n26zl0|I wanted to say t...|[i, wanted, to, s...|(2214,[0,1,2,4,5,...|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "vectorized_corpus.document_dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:=====================================================>(198 + 2) / 200]\r"
     ]
    }
   ],
   "source": [
    "corpus_iterator = vectorized_corpus.get_vectorized_column_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gensim.models.ldamodel : 2022-02-21 12:37:34,818 : INFO : using asymmetric alpha [0.20349778, 0.15460682, 0.124657474, 0.10442834, 0.08984803, 0.07884031, 0.070235424, 0.06332404, 0.057651002, 0.052910853]\n",
      "gensim.models.ldamodel : 2022-02-21 12:37:34,821 : INFO : using symmetric eta at 0.1\n",
      "gensim.models.ldamodel : 2022-02-21 12:37:34,822 : INFO : using serial LDA version on this node\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2022-02-21 12:37:34.831240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gensim.models.ldamulticore : 2022-02-21 12:37:37,284 : INFO : running online LDA training, 10 topics, 1 passes over the supplied corpus of 38 documents, updating every 6000 documents, evaluating every ~38 documents, iterating 1000x with a convergence threshold of 0.001000\n",
      "gensim.models.ldamulticore : 2022-02-21 12:37:37,286 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "gensim.models.ldamulticore : 2022-02-21 12:37:37,290 : INFO : training LDA model using 3 processes\n",
      "gensim.models.ldamulticore : 2022-02-21 12:37:38,046 : INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #38/38, outstanding queue size 1\n",
      "gensim.models.ldamodel : 2022-02-21 12:37:38,779 : INFO : topic #9 (0.053): 0.035*\"que\" + 0.027*\"de\" + 0.023*\"la\" + 0.021*\"y\" + 0.019*\"a\" + 0.016*\"el\" + 0.015*\"en\" + 0.014*\"no\" + 0.014*\"es\" + 0.013*\"vida\"\n",
      "gensim.models.ldamodel : 2022-02-21 12:37:38,783 : INFO : topic #8 (0.058): 0.000*\"to\" + 0.000*\"the\" + 0.000*\"and\" + 0.000*\"is\" + 0.000*\"i\" + 0.000*\"a\" + 0.000*\"with\" + 0.000*\"it\" + 0.000*\"jews\" + 0.000*\"that\"\n",
      "gensim.models.ldamodel : 2022-02-21 12:37:38,795 : INFO : topic #2 (0.125): 0.011*\"a\" + 0.011*\"i\" + 0.011*\"me\" + 0.011*\"the\" + 0.009*\"is\" + 0.009*\"please\" + 0.009*\"us\" + 0.006*\"for\" + 0.006*\"feedback\" + 0.006*\"thanks\"\n",
      "gensim.models.ldamodel : 2022-02-21 12:37:38,796 : INFO : topic #1 (0.155): 0.039*\"i\" + 0.033*\"the\" + 0.028*\"to\" + 0.022*\"a\" + 0.021*\"and\" + 0.014*\"of\" + 0.011*\"that\" + 0.010*\"in\" + 0.010*\"this\" + 0.009*\"my\"\n",
      "gensim.models.ldamodel : 2022-02-21 12:37:38,800 : INFO : topic #0 (0.203): 0.033*\"que\" + 0.022*\"la\" + 0.018*\"de\" + 0.018*\"a\" + 0.016*\"y\" + 0.016*\"es\" + 0.014*\"lo\" + 0.013*\"no\" + 0.012*\"vida\" + 0.012*\"en\"\n",
      "gensim.models.ldamodel : 2022-02-21 12:37:38,803 : INFO : topic diff=6.683311, rho=1.000000\n",
      "gensim.models.ldamodel : 2022-02-21 12:37:38,960 : INFO : -7.339 per-word bound, 161.9 perplexity estimate based on a held-out corpus of 38 documents with 6406 words\n"
     ]
    }
   ],
   "source": [
    "lda_model = ic.GensimLDAModel(corpus_iterator, \"sample_lda\", index, num_topics=10)\n",
    "\n",
    "print(\"Starting training at\", datetime.now())\n",
    "lda_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>top_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>que la de a y es lo no vida en el te me una se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i the to a and of that in this my for is you w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>a i me the is please us for feedback thanks to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>que de la y en no a el es vida te lo una un to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>the and you to scripts with can for these toy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>and the a to i is que for it in la de me of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>you the of a for i it your to mags do in if an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>melatonin sending virtual lt;/3 in lt;3 hrs 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>i a to and the is in nice just have with it th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>que de la y a el en no es vida lo un una si te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id                                          top_terms\n",
       "0         0  que la de a y es lo no vida en el te me una se...\n",
       "1         1  i the to a and of that in this my for is you w...\n",
       "2         2  a i me the is please us for feedback thanks to...\n",
       "3         3  que de la y en no a el es vida te lo una un to...\n",
       "4         4  the and you to scripts with can for these toy ...\n",
       "5         5  and the a to i is que for it in la de me of th...\n",
       "6         6  you the of a for i it your to mags do in if an...\n",
       "7         7  melatonin sending virtual lt;/3 in lt;3 hrs 32...\n",
       "8         8  i a to and the is in nice just have with it th...\n",
       "9         9  que de la y a el en no es vida lo un una si te..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_top_words_as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('que', 0.033466827),\n",
       "   ('la', 0.021855572),\n",
       "   ('de', 0.01814427),\n",
       "   ('a', 0.017571624),\n",
       "   ('y', 0.015609357),\n",
       "   ('es', 0.0156065235),\n",
       "   ('lo', 0.013540798),\n",
       "   ('no', 0.013000362),\n",
       "   ('vida', 0.012253153),\n",
       "   ('en', 0.012138069),\n",
       "   ('el', 0.0115247555),\n",
       "   ('te', 0.010641693),\n",
       "   ('me', 0.010159906),\n",
       "   ('una', 0.008095273),\n",
       "   ('sentido', 0.007598698),\n",
       "   ('un', 0.0074862987),\n",
       "   ('pero', 0.007056793),\n",
       "   ('mi', 0.0063557494),\n",
       "   ('por', 0.0061084973),\n",
       "   ('si', 0.0056476262)]),\n",
       " (1,\n",
       "  [('i', 0.038976073),\n",
       "   ('the', 0.03282222),\n",
       "   ('to', 0.028178835),\n",
       "   ('a', 0.022003897),\n",
       "   ('and', 0.020558286),\n",
       "   ('of', 0.01441212),\n",
       "   ('that', 0.010915627),\n",
       "   ('in', 0.01048467),\n",
       "   ('this', 0.009951461),\n",
       "   ('my', 0.009497926),\n",
       "   ('for', 0.0092457),\n",
       "   ('is', 0.008750445),\n",
       "   ('you', 0.008525668),\n",
       "   ('was', 0.00812873),\n",
       "   ('just', 0.00785081),\n",
       "   ('have', 0.0075670634),\n",
       "   ('it', 0.0075492915),\n",
       "   ('be', 0.006701196),\n",
       "   ('with', 0.0059494213),\n",
       "   ('me', 0.005636731)]),\n",
       " (2,\n",
       "  [('a', 0.011248298),\n",
       "   ('i', 0.011247513),\n",
       "   ('me', 0.011247313),\n",
       "   ('the', 0.011246408),\n",
       "   ('is', 0.008505013),\n",
       "   ('please', 0.008504238),\n",
       "   ('us', 0.0085037425),\n",
       "   ('for', 0.0057622707),\n",
       "   ('feedback', 0.00576193),\n",
       "   ('thanks', 0.005761817),\n",
       "   ('to', 0.005761791),\n",
       "   ('have', 0.0057616187),\n",
       "   ('balling', 0.005761397),\n",
       "   ('no', 0.005761396),\n",
       "   ('purposely', 0.0057613812),\n",
       "   ('trust', 0.0057613705),\n",
       "   ('on', 0.0057612667),\n",
       "   ('he', 0.005761241),\n",
       "   ('get', 0.005761215),\n",
       "   ('blue', 0.005761171)]),\n",
       " (3,\n",
       "  [('que', 0.035923645),\n",
       "   ('de', 0.019851776),\n",
       "   ('la', 0.017850997),\n",
       "   ('y', 0.017015109),\n",
       "   ('en', 0.01671907),\n",
       "   ('no', 0.014375064),\n",
       "   ('a', 0.01223551),\n",
       "   ('el', 0.011585221),\n",
       "   ('es', 0.010753159),\n",
       "   ('vida', 0.009303085),\n",
       "   ('te', 0.00921786),\n",
       "   ('lo', 0.008990964),\n",
       "   ('una', 0.008400721),\n",
       "   ('un', 0.0077725416),\n",
       "   ('to', 0.007115421),\n",
       "   ('pero', 0.0064797043),\n",
       "   ('me', 0.006478722),\n",
       "   ('por', 0.006284144),\n",
       "   ('sentido', 0.006198415),\n",
       "   ('vos', 0.0061203446)]),\n",
       " (4,\n",
       "  [('the', 0.021587592),\n",
       "   ('and', 0.019803302),\n",
       "   ('you', 0.012666641),\n",
       "   ('to', 0.012665672),\n",
       "   ('scripts', 0.010883675),\n",
       "   ('with', 0.010883058),\n",
       "   ('can', 0.009099982),\n",
       "   ('for', 0.009099251),\n",
       "   ('these', 0.007315987),\n",
       "   ('toy', 0.007315556),\n",
       "   ('your', 0.0073145377),\n",
       "   ('this', 0.007313703),\n",
       "   ('a', 0.007313442),\n",
       "   ('sex', 0.005531393),\n",
       "   ('of', 0.0055312915),\n",
       "   ('all', 0.005531084),\n",
       "   ('how', 0.0055310507),\n",
       "   ('vr', 0.005530807),\n",
       "   ('that', 0.005530731),\n",
       "   ('in', 0.0055306284)]),\n",
       " (5,\n",
       "  [('and', 0.021815764),\n",
       "   ('the', 0.020292332),\n",
       "   ('a', 0.020202225),\n",
       "   ('to', 0.017546691),\n",
       "   ('i', 0.016297726),\n",
       "   ('is', 0.0119794225),\n",
       "   ('que', 0.011789952),\n",
       "   ('for', 0.0103210285),\n",
       "   ('it', 0.010075532),\n",
       "   ('in', 0.009952543),\n",
       "   ('la', 0.008573328),\n",
       "   ('de', 0.007906935),\n",
       "   ('me', 0.0072469153),\n",
       "   ('of', 0.0071716956),\n",
       "   ('that', 0.0070578777),\n",
       "   ('you', 0.0065591577),\n",
       "   ('was', 0.0064788624),\n",
       "   ('en', 0.0061614388),\n",
       "   ('y', 0.0061305636),\n",
       "   ('this', 0.005909571)]),\n",
       " (6,\n",
       "  [('you', 0.016289568),\n",
       "   ('the', 0.014446202),\n",
       "   ('of', 0.013775225),\n",
       "   ('a', 0.013283937),\n",
       "   ('for', 0.012236111),\n",
       "   ('i', 0.012026727),\n",
       "   ('it', 0.011216578),\n",
       "   ('your', 0.009746853),\n",
       "   ('to', 0.009297464),\n",
       "   ('mags', 0.00805805),\n",
       "   ('do', 0.008056922),\n",
       "   ('in', 0.0077285147),\n",
       "   ('if', 0.0074364897),\n",
       "   ('and', 0.006832314),\n",
       "   ('with', 0.0065874266),\n",
       "   ('so', 0.0064903456),\n",
       "   ('have', 0.006409599),\n",
       "   ('mark', 0.006092821),\n",
       "   ('be', 0.0060927873),\n",
       "   (\"i'm\", 0.006092255)]),\n",
       " (7,\n",
       "  [('melatonin', 0.00463065),\n",
       "   ('sending', 0.0046305843),\n",
       "   ('virtual', 0.004630414),\n",
       "   ('lt;/3', 0.004630411),\n",
       "   ('in', 0.004630181),\n",
       "   ('lt;3', 0.0046301647),\n",
       "   ('hrs', 0.004630115),\n",
       "   ('32', 0.0046300236),\n",
       "   ('a', 0.004629997),\n",
       "   ('haven’t', 0.0046298928),\n",
       "   ('spiraled', 0.004629818),\n",
       "   ('you', 0.0046297773),\n",
       "   ('some', 0.0046295873),\n",
       "   ('slept', 0.0046294965),\n",
       "   ('lil', 0.004629324),\n",
       "   ('just', 0.004629067),\n",
       "   ('to', 0.00042125618),\n",
       "   ('and', 0.00042125618),\n",
       "   ('the', 0.00042125615),\n",
       "   ('i', 0.00042125612)]),\n",
       " (8,\n",
       "  [('i', 0.00045167122),\n",
       "   ('a', 0.00045167122),\n",
       "   ('to', 0.00045167122),\n",
       "   ('and', 0.00045167122),\n",
       "   ('the', 0.00045167122),\n",
       "   ('is', 0.00045167122),\n",
       "   ('in', 0.00045167116),\n",
       "   ('nice', 0.00045167116),\n",
       "   ('just', 0.00045167116),\n",
       "   ('have', 0.00045167116),\n",
       "   ('with', 0.00045167116),\n",
       "   ('it', 0.00045167116),\n",
       "   ('that', 0.00045167116),\n",
       "   ('this', 0.00045167116),\n",
       "   ('would', 0.00045167116),\n",
       "   ('was', 0.00045167116),\n",
       "   ('my', 0.00045167116),\n",
       "   ('me', 0.00045167116),\n",
       "   ('jews', 0.00045167116),\n",
       "   ('you', 0.00045167116)]),\n",
       " (9,\n",
       "  [('que', 0.035332233),\n",
       "   ('de', 0.027166188),\n",
       "   ('la', 0.022594495),\n",
       "   ('y', 0.020822646),\n",
       "   ('a', 0.01918215),\n",
       "   ('el', 0.016362498),\n",
       "   ('en', 0.014549394),\n",
       "   ('no', 0.014018135),\n",
       "   ('es', 0.013645112),\n",
       "   ('vida', 0.013334439),\n",
       "   ('lo', 0.012656302),\n",
       "   ('un', 0.009837367),\n",
       "   ('una', 0.0098304935),\n",
       "   ('si', 0.008830712),\n",
       "   ('te', 0.008692744),\n",
       "   ('me', 0.0072922152),\n",
       "   ('sentido', 0.006816047),\n",
       "   ('como', 0.0061677587),\n",
       "   ('por', 0.006068385),\n",
       "   ('para', 0.0058433046)])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_top_words()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "645e6807a54f1780e2a687ae083eb2a94c3bf70f4809b5f746590e8ef179a45c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ihop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
