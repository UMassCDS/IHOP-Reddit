{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline LDA model\n",
    "This notebook gives an overview of how to train an LDA model from the Reddit data.\n",
    "\n",
    "The input is a joined submissions and commends dataframe as produced by `notebooks/bagOfWords_preprocessing_databricks.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 13:43:27 WARN Utils: Your hostname, Kurt resolves to a loopback address: 127.0.1.1; using 192.168.0.11 instead (on interface wlp4s0)\n",
      "22/02/22 13:43:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/22 13:43:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/02/22 13:43:29 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark configuration:\n",
      "[('spark.app.startTime', '1645555408216'), ('spark.driver.port', '35221'), ('spark.app.id', 'local-1645555410249'), ('spark.executor.id', 'driver'), ('spark.app.name', 'baseline lda'), ('spark.driver.memory', '8G'), ('spark.driver.host', '192.168.0.11'), ('spark.sql.warehouse.dir', 'file:/home/virginia/Documents/CenterForDataScience/ZuckermanProj/IHOP/notebooks/spark-warehouse'), ('spark.rdd.compress', 'True'), ('spark.serializer.objectStreamReset', '100'), ('spark.master', 'local[*]'), ('spark.submit.pyFiles', ''), ('spark.submit.deployMode', 'client'), ('spark.executor.extraLibraryPath', '/home/virginia/hadoop-3.3.1/lib/native'), ('spark.ui.showConsoleProgress', 'true'), ('spark.driver.extraLibraryPath', '/home/virginia/hadoop-3.3.1/lib/native')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import ihop.utils\n",
    "spark = ihop.utils.get_spark_session(\"baseline lda\")\n",
    "\n",
    "input_data = spark.read.load(\n",
    "    \"../data/bagOfWords/2021-05_to_2021-06_joined_submissions_comments_5percentTopUsersExcludedFromComments_02102022.parquet\").limit(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+------+-----+--------------------+--------------------+--------------------+-----------+------------------+-----------+----------+--------------+---------+---------------+--------------------+--------------------+--------------------------+\n",
      "|subreddit|    author|created_utc|    id|score|            selftext|               title|                 url|fullname_id|comments_subreddit|comments_id| parent_id|comments_score|  link_id|comments_author|                body|comments_created_utc|time_to_comment_in_seconds|\n",
      "+---------+----------+-----------+------+-----+--------------------+--------------------+--------------------+-----------+------------------+-----------+----------+--------------+---------+---------------+--------------------+--------------------+--------------------------+\n",
      "| Market76|Apostle-II| 1619827212|n26p5s|    2|Don’t use 5.56 an...|H: 30k 50cal and ...|https://www.reddi...|  t3_n26p5s|          Market76|    gwhjcmt| t3_n26p5s|             1|t3_n26p5s|     Apostle-II|    Ultracite 5.56**|          1619827249|                      37.0|\n",
      "| Market76|Apostle-II| 1619827212|n26p5s|    2|Don’t use 5.56 an...|H: 30k 50cal and ...|https://www.reddi...|  t3_n26p5s|          Market76|    gwhjsu2|t1_gwhjnyi|             1|t3_n26p5s|     Apostle-II|                 Gt?|          1619827475|                     263.0|\n",
      "| Market76|Apostle-II| 1619827212|n26p5s|    2|Don’t use 5.56 an...|H: 30k 50cal and ...|https://www.reddi...|  t3_n26p5s|          Market76|    gwhjuvb|t1_gwhjolr|             1|t3_n26p5s|     Apostle-II|Sorry, other pers...|          1619827503|                     291.0|\n",
      "| Market76|Apostle-II| 1619827212|n26p5s|    2|Don’t use 5.56 an...|H: 30k 50cal and ...|https://www.reddi...|  t3_n26p5s|          Market76|    gwhkou5|t1_gwhkglx|             1|t3_n26p5s|     Apostle-II|You mind splittin...|          1619827926|                     714.0|\n",
      "| Market76|Apostle-II| 1619827212|n26p5s|    2|Don’t use 5.56 an...|H: 30k 50cal and ...|https://www.reddi...|  t3_n26p5s|          Market76|    gwhlzxz|t1_gwhjpby|             1|t3_n26p5s|     Apostle-II|15k is what I’m l...|          1619828596|                    1384.0|\n",
      "+---------+----------+-----------+------+-----+--------------------+--------------------+--------------------+-----------+------------------+-----------+----------+--------------+---------+---------------+--------------------+--------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a simple LDA model using Gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import ihop.clustering as ic\n",
    "import ihop.text_processing as itp\n",
    "\n",
    "# Read in the joined data, collecting all the comments for each submission\n",
    "# Any desired filtering by time stamps can be done here\n",
    "corpus = itp.SparkCorpus.init_from_joined_dataframe(input_data)\n",
    "\n",
    "# Tokenize the document, then create an id to word index and vectorize each document\n",
    "# This is where you would set minimum and maximum document frequency and minimum term frequency, passed to Spark CountVectorizer\n",
    "pipeline = itp.SparkTextPreprocessingPipeline('document_text')\n",
    "transformed = pipeline.fit_transform(corpus.document_dataframe)\n",
    "vectorized_corpus = itp.SparkCorpus(transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX DETAILS:\n",
      "Vocab size: 11\n",
      "0 a\n",
      "1 the\n",
      "2 i\n",
      "3 to\n",
      "4 and\n",
      "5 of\n",
      "6 for\n",
      "7 is\n",
      "8 you\n",
      "9 in\n"
     ]
    }
   ],
   "source": [
    "index = pipeline.get_id_to_word()\n",
    "print(\"INDEX DETAILS:\")\n",
    "print(\"Vocab size:\", len(index))\n",
    "for k in range(10):\n",
    "    print(k, index[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+--------------------+--------------------+--------------------+\n",
      "|    id|       subreddit|       document_text|           tokenized|          vectorized|\n",
      "+------+----------------+--------------------+--------------------+--------------------+\n",
      "|n26uxd|onlyfansgirls101|Cum visit and cha...|[cum, visit, and,...|(11,[4,5],[1.0,1.0])|\n",
      "|n26p5s|        Market76|H: 30k 50cal and ...|[h, 30k, 50cal, a...|(11,[0,1,2,3,4,5,...|\n",
      "|n2725q|PvZGardenWarfare|hey black jews  Nice|[hey, black, jews...|          (11,[],[])|\n",
      "|n27gmk|            ar15|Magazine markings...|[magazine, markin...|(11,[0,1,2,3,4,5,...|\n",
      "|n272yp|          rule34|Bulma - lonely mi...|[bulma, lonely, m...|(11,[0,7,10],[1.0...|\n",
      "|n26rtn|       AskReddit|What is always be...|[what, is, always...|(11,[0,1,2,3,4,5,...|\n",
      "|n26unv|        Columbus|Lost cat in the S...|[lost, cat, in, t...|(11,[0,1,3,4,5,6,...|\n",
      "|n26z8u|      deathgrips|GUYS THEY ARE STI...|[guys, they, are,...|(11,[0,1,2,5,7,10...|\n",
      "|n274xr|     foxholegame|Wardens pushing i...|[wardens, pushing...|(11,[0,1,2,3,4,5,...|\n",
      "|n272kp|           funny|This is my last r...|[this, is, my, la...|(11,[7,10],[2.0,2...|\n",
      "|n276vv|      oculusnsfw|This week we rele...|[this, week, we, ...|(11,[0,1,2,3,4,5,...|\n",
      "|n271bl|         airsoft|Noveske Infidel c...|[noveske, infidel...|(11,[0,1,2,3,4,6,...|\n",
      "|n272h4|       teenagers|Who got the best ...|[who, got, the, b...|(11,[1,8],[1.0,1.0])|\n",
      "|n26uja|         airguns|Tell me a bad guy...|[tell, me, a, bad...|(11,[0,1,7,9,10],...|\n",
      "|n275j4|  40plusGoneWild|I’m waiting for y...|[i’m, waiting, fo...|(11,[0,1,2,5,6,8,...|\n",
      "|n2712w|         stalker|Im i the only one...|[im, i, the, only...|(11,[0,1,2,3,4,5,...|\n",
      "|n273zc|      CSRRacing2|About the last sp...|[about, the, last...|(11,[1,2,3,4,5,6,...|\n",
      "|n278ql|      Warthunder|I defended an ent...|[i, defended, an,...|(11,[0,1,2,3,4,5,...|\n",
      "|n26qdl|          soccer|[Fabrizio Romano]...|[fabrizio, romano...|      (11,[3],[2.0])|\n",
      "|n26zl0|   dwarffortress|I wanted to say t...|[i, wanted, to, s...|(11,[0,1,2,3,4,5,...|\n",
      "+------+----------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorized_corpus.document_dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_iterator = vectorized_corpus.get_vectorized_column_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gensim.models.ldamodel : 2022-02-22 13:45:16,254 : INFO : using asymmetric alpha [0.20349778, 0.15460682, 0.124657474, 0.10442834, 0.08984803, 0.07884031, 0.070235424, 0.06332404, 0.057651002, 0.052910853]\n",
      "gensim.models.ldamodel : 2022-02-22 13:45:16,256 : INFO : using symmetric eta at 0.1\n",
      "gensim.models.ldamodel : 2022-02-22 13:45:16,257 : INFO : using serial LDA version on this node\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2022-02-22 13:45:16.265508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gensim.models.ldamulticore : 2022-02-22 13:45:17,926 : INFO : running online LDA training, 10 topics, 1 passes over the supplied corpus of 38 documents, updating every 6000 documents, evaluating every ~38 documents, iterating 1000x with a convergence threshold of 0.001000\n",
      "gensim.models.ldamulticore : 2022-02-22 13:45:17,926 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "gensim.models.ldamulticore : 2022-02-22 13:45:17,929 : INFO : training LDA model using 3 processes\n",
      "gensim.models.ldamulticore : 2022-02-22 13:45:48,816 : INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #38/38, outstanding queue size 1\n",
      "gensim.models.ldamodel : 2022-02-22 13:45:49,124 : INFO : topic #9 (0.053): 0.235*\"i\" + 0.145*\"the\" + 0.130*\"and\" + 0.116*\"a\" + 0.112*\"to\" + 0.058*\"is\" + 0.054*\"for\" + 0.047*\"of\" + 0.047*\"in\" + 0.029*\"you\"\n",
      "gensim.models.ldamodel : 2022-02-22 13:45:49,126 : INFO : topic #8 (0.058): 0.091*\"a\" + 0.091*\"the\" + 0.091*\"to\" + 0.091*\"i\" + 0.091*\"and\" + 0.091*\"you\" + 0.091*\"for\" + 0.091*\"of\" + 0.091*\"this\" + 0.091*\"is\"\n",
      "gensim.models.ldamodel : 2022-02-22 13:45:49,128 : INFO : topic #2 (0.125): 0.091*\"a\" + 0.091*\"to\" + 0.091*\"and\" + 0.091*\"the\" + 0.091*\"you\" + 0.091*\"i\" + 0.091*\"for\" + 0.091*\"this\" + 0.091*\"of\" + 0.091*\"in\"\n",
      "gensim.models.ldamodel : 2022-02-22 13:45:49,131 : INFO : topic #1 (0.155): 0.170*\"the\" + 0.170*\"a\" + 0.170*\"for\" + 0.129*\"i\" + 0.129*\"to\" + 0.087*\"you\" + 0.046*\"and\" + 0.046*\"this\" + 0.046*\"in\" + 0.004*\"of\"\n",
      "gensim.models.ldamodel : 2022-02-22 13:45:49,134 : INFO : topic #0 (0.203): 0.149*\"and\" + 0.144*\"to\" + 0.136*\"the\" + 0.096*\"is\" + 0.088*\"you\" + 0.083*\"i\" + 0.075*\"in\" + 0.070*\"a\" + 0.062*\"of\" + 0.053*\"for\"\n",
      "gensim.models.ldamodel : 2022-02-22 13:45:49,136 : INFO : topic diff=3.981022, rho=1.000000\n",
      "gensim.models.ldamodel : 2022-02-22 13:45:49,257 : INFO : -2.521 per-word bound, 5.7 perplexity estimate based on a held-out corpus of 38 documents with 915 words\n"
     ]
    }
   ],
   "source": [
    "lda_model = ic.GensimLDAModel(corpus_iterator, \"sample_lda\", index, num_topics=10)\n",
    "\n",
    "print(\"Starting training at\", datetime.now())\n",
    "lda_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>top_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>and to the is you i in a of for this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the a for i to you and this in of is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>a to and the you i for this of in is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a to the and of you this for i is in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a i to the of and this for you in is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>a to the and i this you of for in is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>the to and this for of you a i in is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>a the to and i you for of is in this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>a the to i and you for of this is in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>i the and a to is for of in you this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id                             top_terms\n",
       "0         0  and to the is you i in a of for this\n",
       "1         1  the a for i to you and this in of is\n",
       "2         2  a to and the you i for this of in is\n",
       "3         3  a to the and of you this for i is in\n",
       "4         4  a i to the of and this for you in is\n",
       "5         5  a to the and i this you of for in is\n",
       "6         6  the to and this for of you a i in is\n",
       "7         7  a the to and i you for of is in this\n",
       "8         8  a the to i and you for of this is in\n",
       "9         9  i the and a to is for of in you this"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_top_words_as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('and', 0.14881942),\n",
       "   ('to', 0.14447534),\n",
       "   ('the', 0.13576007),\n",
       "   ('is', 0.09643146),\n",
       "   ('you', 0.087731265),\n",
       "   ('i', 0.08338675),\n",
       "   ('in', 0.0746347),\n",
       "   ('a', 0.07032274),\n",
       "   ('of', 0.06153272),\n",
       "   ('for', 0.05283381),\n",
       "   ('this', 0.044071767)]),\n",
       " (1,\n",
       "  [('the', 0.17007343),\n",
       "   ('a', 0.17001452),\n",
       "   ('for', 0.16994862),\n",
       "   ('i', 0.12872131),\n",
       "   ('to', 0.12867348),\n",
       "   ('you', 0.08697742),\n",
       "   ('and', 0.045754578),\n",
       "   ('this', 0.045746256),\n",
       "   ('in', 0.045607455),\n",
       "   ('of', 0.004241557),\n",
       "   ('is', 0.0042413757)]),\n",
       " (2,\n",
       "  [('a', 0.09143674),\n",
       "   ('to', 0.0912339),\n",
       "   ('and', 0.09104566),\n",
       "   ('the', 0.0909628),\n",
       "   ('you', 0.09093136),\n",
       "   ('i', 0.090870544),\n",
       "   ('for', 0.09074566),\n",
       "   ('this', 0.090735145),\n",
       "   ('of', 0.090728745),\n",
       "   ('in', 0.090699814),\n",
       "   ('is', 0.09060963)]),\n",
       " (3,\n",
       "  [('a', 0.09099901),\n",
       "   ('to', 0.09097387),\n",
       "   ('the', 0.09094788),\n",
       "   ('and', 0.09091422),\n",
       "   ('of', 0.090911366),\n",
       "   ('you', 0.09089516),\n",
       "   ('this', 0.09089499),\n",
       "   ('for', 0.09088799),\n",
       "   ('i', 0.09087923),\n",
       "   ('is', 0.090852335),\n",
       "   ('in', 0.090844035)]),\n",
       " (4,\n",
       "  [('a', 0.35246488),\n",
       "   ('i', 0.14819705),\n",
       "   ('to', 0.1047328),\n",
       "   ('the', 0.10039188),\n",
       "   ('of', 0.06562217),\n",
       "   ('and', 0.052585296),\n",
       "   ('this', 0.039551653),\n",
       "   ('for', 0.03954465),\n",
       "   ('you', 0.03519979),\n",
       "   ('in', 0.03519935),\n",
       "   ('is', 0.026510425)]),\n",
       " (5,\n",
       "  [('a', 0.09091399),\n",
       "   ('to', 0.09091257),\n",
       "   ('the', 0.09091117),\n",
       "   ('and', 0.09090947),\n",
       "   ('i', 0.09090938),\n",
       "   ('this', 0.09090798),\n",
       "   ('you', 0.09090769),\n",
       "   ('of', 0.090907514),\n",
       "   ('for', 0.09090739),\n",
       "   ('in', 0.09090682),\n",
       "   ('is', 0.090905994)]),\n",
       " (6,\n",
       "  [('the', 0.2130022),\n",
       "   ('to', 0.13178775),\n",
       "   ('and', 0.11928941),\n",
       "   ('this', 0.088074125),\n",
       "   ('for', 0.081829324),\n",
       "   ('of', 0.081828035),\n",
       "   ('you', 0.06933313),\n",
       "   ('a', 0.06308647),\n",
       "   ('i', 0.0568339),\n",
       "   ('in', 0.050591473),\n",
       "   ('is', 0.04434421)]),\n",
       " (7,\n",
       "  [('a', 0.09090925),\n",
       "   ('the', 0.09090924),\n",
       "   ('to', 0.090909205),\n",
       "   ('and', 0.09090913),\n",
       "   ('i', 0.09090909),\n",
       "   ('you', 0.09090908),\n",
       "   ('for', 0.09090905),\n",
       "   ('of', 0.09090901),\n",
       "   ('is', 0.09090901),\n",
       "   ('in', 0.090909),\n",
       "   ('this', 0.090909)]),\n",
       " (8,\n",
       "  [('a', 0.090909116),\n",
       "   ('the', 0.09090911),\n",
       "   ('to', 0.09090911),\n",
       "   ('i', 0.090909086),\n",
       "   ('and', 0.090909086),\n",
       "   ('you', 0.090909086),\n",
       "   ('for', 0.09090908),\n",
       "   ('of', 0.09090907),\n",
       "   ('this', 0.09090907),\n",
       "   ('is', 0.090909064),\n",
       "   ('in', 0.09090906)]),\n",
       " (9,\n",
       "  [('i', 0.23494394),\n",
       "   ('the', 0.14471075),\n",
       "   ('and', 0.1302766),\n",
       "   ('a', 0.11584375),\n",
       "   ('to', 0.11222704),\n",
       "   ('is', 0.058101464),\n",
       "   ('for', 0.054494806),\n",
       "   ('of', 0.047277052),\n",
       "   ('in', 0.047273614),\n",
       "   ('you', 0.029229732),\n",
       "   ('this', 0.025621226)])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_top_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Coherence': -0.2828817524014652}\n"
     ]
    }
   ],
   "source": [
    "print(lda_model.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.08139257),\n",
       " (1, 0.11091771),\n",
       " (4, 0.14634702),\n",
       " (6, 0.0539086),\n",
       " (9, 0.23356293)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_term_topics('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'sample_lda',\n",
       " 'num_topics': 10,\n",
       " 'alpha': [0.20349778,\n",
       "  0.15460682,\n",
       "  0.124657474,\n",
       "  0.10442834,\n",
       "  0.08984803,\n",
       "  0.07884031,\n",
       "  0.070235424,\n",
       "  0.06332404,\n",
       "  0.057651002,\n",
       "  0.052910853],\n",
       " 'eta': [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       " 'decay': 0.5,\n",
       " 'offset': 1.0,\n",
       " 'iterations': 1000,\n",
       " 'random_state_seed': <function RandomState.seed>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n26uxd': [(9, 0.017636975),\n",
       "  (8, 0.019217027),\n",
       "  (7, 0.021108042),\n",
       "  (6, 0.023412019),\n",
       "  (5, 0.026280139),\n",
       "  (4, 0.029951965),\n",
       "  (3, 0.034809504),\n",
       "  (2, 0.041552596),\n",
       "  (1, 0.051575977),\n",
       "  (0, 0.73445576)],\n",
       " 'n26p5s': [(0, 0.965333)],\n",
       " 'n2725q': [(9, 0.052910846),\n",
       "  (8, 0.057650995),\n",
       "  (7, 0.063324034),\n",
       "  (6, 0.07023542),\n",
       "  (5, 0.0788403),\n",
       "  (4, 0.08984802),\n",
       "  (3, 0.10442833),\n",
       "  (2, 0.12465746),\n",
       "  (1, 0.1546068),\n",
       "  (0, 0.20349775)],\n",
       " 'n27gmk': [(0, 0.29489407), (4, 0.6767942)],\n",
       " 'n272yp': [(9, 0.013227739),\n",
       "  (8, 0.014412778),\n",
       "  (7, 0.01583104),\n",
       "  (6, 0.017559022),\n",
       "  (5, 0.019710114),\n",
       "  (3, 0.026107145),\n",
       "  (2, 0.031164479),\n",
       "  (1, 0.03885591),\n",
       "  (4, 0.28107932),\n",
       "  (0, 0.54205245)],\n",
       " 'n26rtn': [(0, 0.4723073), (6, 0.4986023)],\n",
       " 'n26unv': [(0, 0.9715137)],\n",
       " 'n26z8u': [(3, 0.010442853),\n",
       "  (2, 0.012465781),\n",
       "  (1, 0.01552637),\n",
       "  (4, 0.33853054),\n",
       "  (0, 0.5907382)],\n",
       " 'n274xr': [(6, 0.9687534)],\n",
       " 'n272kp': [(9, 0.010582193),\n",
       "  (8, 0.011530223),\n",
       "  (7, 0.012664834),\n",
       "  (6, 0.014047332),\n",
       "  (5, 0.015768094),\n",
       "  (4, 0.017970815),\n",
       "  (3, 0.020885717),\n",
       "  (2, 0.024931584),\n",
       "  (1, 0.031001091),\n",
       "  (0, 0.8406181)],\n",
       " 'n276vv': [(6, 0.9759663)],\n",
       " 'n271bl': [(4, 0.9563092)],\n",
       " 'n272h4': [(9, 0.01763697),\n",
       "  (8, 0.01921702),\n",
       "  (7, 0.021108035),\n",
       "  (6, 0.023412041),\n",
       "  (5, 0.02628013),\n",
       "  (4, 0.029951429),\n",
       "  (3, 0.034809493),\n",
       "  (2, 0.041552573),\n",
       "  (1, 0.052051622),\n",
       "  (0, 0.7339807)],\n",
       " 'n26uja': [(6, 0.010033712),\n",
       "  (5, 0.01126292),\n",
       "  (4, 0.012837338),\n",
       "  (3, 0.014918364),\n",
       "  (2, 0.017808262),\n",
       "  (1, 0.022224052),\n",
       "  (0, 0.8860745)],\n",
       " 'n275j4': [(3, 0.010442853),\n",
       "  (2, 0.012465781),\n",
       "  (1, 0.015600461),\n",
       "  (0, 0.92020863)],\n",
       " 'n2712w': [(4, 0.39816612), (9, 0.5720134)],\n",
       " 'n273zc': [(0, 0.4483183), (9, 0.5297863)],\n",
       " 'n278ql': [(9, 0.9742103)],\n",
       " 'n26qdl': [(9, 0.017636968),\n",
       "  (8, 0.019217018),\n",
       "  (7, 0.021108033),\n",
       "  (6, 0.023411974),\n",
       "  (5, 0.026280126),\n",
       "  (4, 0.029952008),\n",
       "  (3, 0.034809485),\n",
       "  (2, 0.04155256),\n",
       "  (1, 0.051912516),\n",
       "  (0, 0.73411936)],\n",
       " 'n26zl0': [(6, 0.36152434), (9, 0.63005435)],\n",
       " 'n27gy2': [(4, 0.98311496)],\n",
       " 'n274qm': [(7, 0.010554018),\n",
       "  (6, 0.011705979),\n",
       "  (5, 0.013140066),\n",
       "  (4, 0.01497724),\n",
       "  (3, 0.017404746),\n",
       "  (2, 0.020776287),\n",
       "  (1, 0.025962869),\n",
       "  (0, 0.8670518)],\n",
       " 'n27fae': [(1, 0.011958328), (0, 0.016193843), (9, 0.9265405)],\n",
       " 'n26x3u': [(9, 0.46828002), (0, 0.4993356)],\n",
       " 'n27f7w': [(9, 0.017636964),\n",
       "  (8, 0.019217014),\n",
       "  (7, 0.02110803),\n",
       "  (6, 0.0234119),\n",
       "  (5, 0.026280122),\n",
       "  (4, 0.029954448),\n",
       "  (3, 0.034809478),\n",
       "  (2, 0.041552547),\n",
       "  (0, 0.06875057),\n",
       "  (1, 0.7172789)],\n",
       " 'n26wgo': [(4, 0.10844513), (9, 0.88254476)],\n",
       " 'n27gm7': [(9, 0.9886409)],\n",
       " 'n26xgk': [(6, 0.9665002)],\n",
       " 'n27gpy': [(6, 0.97711605)],\n",
       " 'n26pnc': [(9, 0.017636968),\n",
       "  (8, 0.019217018),\n",
       "  (7, 0.021108033),\n",
       "  (6, 0.023411965),\n",
       "  (5, 0.026280126),\n",
       "  (4, 0.029951576),\n",
       "  (3, 0.034809485),\n",
       "  (2, 0.041552562),\n",
       "  (0, 0.070075884),\n",
       "  (1, 0.7159564)],\n",
       " 'n2710k': [(0, 0.013954109), (1, 0.29477876), (9, 0.6520007)],\n",
       " 'n26rob': [(3, 0.010442847),\n",
       "  (2, 0.012465771),\n",
       "  (1, 0.015567583),\n",
       "  (0, 0.9202418)],\n",
       " 'n27ego': [(0, 0.97249293)],\n",
       " 'n270nt': [(4, 0.31346437), (6, 0.653949)],\n",
       " 'n27dwy': [(9, 0.052910846),\n",
       "  (8, 0.057650995),\n",
       "  (7, 0.063324034),\n",
       "  (6, 0.07023542),\n",
       "  (5, 0.0788403),\n",
       "  (4, 0.08984802),\n",
       "  (3, 0.10442833),\n",
       "  (2, 0.12465746),\n",
       "  (1, 0.1546068),\n",
       "  (0, 0.20349775)],\n",
       " 'n27362': [(0, 0.9725015)],\n",
       " 'n2796a': [(9, 0.013227734),\n",
       "  (8, 0.014412772),\n",
       "  (7, 0.015831035),\n",
       "  (6, 0.01755897),\n",
       "  (5, 0.019710107),\n",
       "  (4, 0.022468522),\n",
       "  (3, 0.026107132),\n",
       "  (2, 0.031164456),\n",
       "  (1, 0.039019577),\n",
       "  (0, 0.8004997)],\n",
       " 'n26vy2': [(0, 0.9826625)]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_corpus_iter = vectorized_corpus.get_vectorized_column_iterator(use_id_col=True)\n",
    "doc_topics = lda_model.get_topic_assigments(id_corpus_iter)\n",
    "print(len(doc_topics))\n",
    "doc_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sample_lda</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n26uxd</td>\n",
       "      <td>9</td>\n",
       "      <td>onlyfansgirls101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n26p5s</td>\n",
       "      <td>0</td>\n",
       "      <td>Market76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n2725q</td>\n",
       "      <td>9</td>\n",
       "      <td>PvZGardenWarfare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n27gmk</td>\n",
       "      <td>0</td>\n",
       "      <td>ar15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n272yp</td>\n",
       "      <td>9</td>\n",
       "      <td>rule34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n26rtn</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n26unv</td>\n",
       "      <td>0</td>\n",
       "      <td>Columbus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n26z8u</td>\n",
       "      <td>3</td>\n",
       "      <td>deathgrips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n274xr</td>\n",
       "      <td>6</td>\n",
       "      <td>foxholegame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n272kp</td>\n",
       "      <td>9</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>n276vv</td>\n",
       "      <td>6</td>\n",
       "      <td>oculusnsfw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>n271bl</td>\n",
       "      <td>4</td>\n",
       "      <td>airsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>n272h4</td>\n",
       "      <td>9</td>\n",
       "      <td>teenagers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n26uja</td>\n",
       "      <td>6</td>\n",
       "      <td>airguns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>n275j4</td>\n",
       "      <td>3</td>\n",
       "      <td>40plusGoneWild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>n2712w</td>\n",
       "      <td>4</td>\n",
       "      <td>stalker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>n273zc</td>\n",
       "      <td>0</td>\n",
       "      <td>CSRRacing2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>n278ql</td>\n",
       "      <td>9</td>\n",
       "      <td>Warthunder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>n26qdl</td>\n",
       "      <td>9</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>n26zl0</td>\n",
       "      <td>6</td>\n",
       "      <td>dwarffortress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>n27gy2</td>\n",
       "      <td>4</td>\n",
       "      <td>argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>n274qm</td>\n",
       "      <td>7</td>\n",
       "      <td>CaliforniaSwingers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>n27fae</td>\n",
       "      <td>1</td>\n",
       "      <td>LobaMains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>n26x3u</td>\n",
       "      <td>9</td>\n",
       "      <td>CleaningTips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>n27f7w</td>\n",
       "      <td>9</td>\n",
       "      <td>smoking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>n26wgo</td>\n",
       "      <td>4</td>\n",
       "      <td>running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>n27gm7</td>\n",
       "      <td>9</td>\n",
       "      <td>AskMtFHRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>n26xgk</td>\n",
       "      <td>6</td>\n",
       "      <td>Tahmkenchmains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>n27gpy</td>\n",
       "      <td>6</td>\n",
       "      <td>DragRaceDownUnder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>n26pnc</td>\n",
       "      <td>9</td>\n",
       "      <td>osugame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>n2710k</td>\n",
       "      <td>0</td>\n",
       "      <td>ecommerce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>n26rob</td>\n",
       "      <td>3</td>\n",
       "      <td>Repsneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>n27ego</td>\n",
       "      <td>0</td>\n",
       "      <td>Asmongold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>n270nt</td>\n",
       "      <td>4</td>\n",
       "      <td>piano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>n27dwy</td>\n",
       "      <td>9</td>\n",
       "      <td>rearpussy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>n27362</td>\n",
       "      <td>0</td>\n",
       "      <td>WarCollege</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>n2796a</td>\n",
       "      <td>9</td>\n",
       "      <td>MadeOfStyrofoam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>n26vy2</td>\n",
       "      <td>0</td>\n",
       "      <td>ChronicIllness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id sample_lda           subreddit\n",
       "0   n26uxd          9    onlyfansgirls101\n",
       "1   n26p5s          0            Market76\n",
       "2   n2725q          9    PvZGardenWarfare\n",
       "3   n27gmk          0                ar15\n",
       "4   n272yp          9              rule34\n",
       "5   n26rtn          0           AskReddit\n",
       "6   n26unv          0            Columbus\n",
       "7   n26z8u          3          deathgrips\n",
       "8   n274xr          6         foxholegame\n",
       "9   n272kp          9               funny\n",
       "10  n276vv          6          oculusnsfw\n",
       "11  n271bl          4             airsoft\n",
       "12  n272h4          9           teenagers\n",
       "13  n26uja          6             airguns\n",
       "14  n275j4          3      40plusGoneWild\n",
       "15  n2712w          4             stalker\n",
       "16  n273zc          0          CSRRacing2\n",
       "17  n278ql          9          Warthunder\n",
       "18  n26qdl          9              soccer\n",
       "19  n26zl0          6       dwarffortress\n",
       "20  n27gy2          4           argentina\n",
       "21  n274qm          7  CaliforniaSwingers\n",
       "22  n27fae          1           LobaMains\n",
       "23  n26x3u          9        CleaningTips\n",
       "24  n27f7w          9             smoking\n",
       "25  n26wgo          4             running\n",
       "26  n27gm7          9           AskMtFHRT\n",
       "27  n26xgk          6      Tahmkenchmains\n",
       "28  n27gpy          6   DragRaceDownUnder\n",
       "29  n26pnc          9             osugame\n",
       "30  n2710k          0           ecommerce\n",
       "31  n26rob          3         Repsneakers\n",
       "32  n27ego          0           Asmongold\n",
       "33  n270nt          4               piano\n",
       "34  n27dwy          9           rearpussy\n",
       "35  n27362          0          WarCollege\n",
       "36  n2796a          9     MadeOfStyrofoam\n",
       "37  n26vy2          0      ChronicIllness"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddits = corpus.document_dataframe.select('id', 'subreddit').toPandas()\n",
    "topics_df = lda_model.get_cluster_results_as_df(vocab_col_name=\"id\", join_df = subreddits)\n",
    "topics_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "645e6807a54f1780e2a687ae083eb2a94c3bf70f4809b5f746590e8ef179a45c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ihop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
